{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T03:28:46.042713Z",
     "iopub.status.busy": "2022-10-27T03:28:46.041900Z",
     "iopub.status.idle": "2022-10-27T03:28:46.056473Z",
     "shell.execute_reply": "2022-10-27T03:28:46.055255Z",
     "shell.execute_reply.started": "2022-10-27T03:28:46.042679Z"
    },
    "tags": []
   },
   "source": [
    "# 想定制自己的文图生成模型吗？想画什么画什么\n",
    "\n",
    "**文图生成有多火，已经不用介绍了。今天主要来分享如何定制自己的文图生成模型，只需要几张图片，即可定制开发自己想要的文图生成模型哦。有问题的话，文末有交流群，欢迎加入！**\n",
    "\n",
    "文图生成任务要求模型根据所提供的描述性文本生成一张与之相对应的图片。这极大地释放了AI的想象力，也激发了人类的创意，给视觉内容创作者、文字内容创作者和大众用户带来了方便。用户可以生成多样化创意图片，并从中汲取创意灵感，打破创意瓶颈，从而可以进行创作出更优质的作品。\n",
    " \n",
    "说到模型，文图生成领域典型的模型有[**OpenAI**](https://openai.com/)提出的[**DALL-E**](https://arxiv.org/pdf/2102.12092.pdf)和[**DALL-E 2**](https://arxiv.org/pdf/2204.06125v1.pdf)，近期，工业界也训练出了更大、更新的文图生成模型，例如[**谷歌**](https://www.google.com)提出的[**Parti**](https://github.com/google-research/parti)和[**Imagen**](https://imagen.research.google)，[**百度**](https://www.baidu.com)提出的[**文心ERNIE-ViLG 2.0**](https://wenxin.baidu.com/ernie-vilg)和[**文心一格**](https://yige.baidu.com)等模型，以及今天二次开发所用到的[**Stable Diffusion**](https://github.com/CompVis/stable-diffusion)模型。\n",
    "\n",
    "\n",
    "[**PaddleNLP**](https://github.com/PaddlePaddle/PaddleNLP)作为一款自然语言处理工具箱，涵盖了多种NLP相关的任务。当前PaddleNLP已经集成了[**6种文图生成模型**](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/taskflow.md#%E6%96%87%E5%9B%BE%E7%94%9F%E6%88%90)，其中**Stable Diffusion**模型位于[目录](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers)，\n",
    "**文心ERNIE-ViLG 2.0**模型位于[目录](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/pipelines/examples/text_to_image)。\n",
    "\n",
    "[**文心ERNIE-ViLG 2.0**](https://arxiv.org/pdf/2210.15257.pdf)在文本生成图像公开权威评测集 MS-COCO 和人工盲评上均超越了[**Stable Diffusion**](https://github.com/CompVis/stable-diffusion)、[**DALL-E 2**](https://arxiv.org/pdf/2204.06125v1.pdf) 等模型，取得了当前该领域的世界最好效果，在**语义可控性**、**图像清晰度**、**中国文化理解**等方面均展现出了显著优势。\n",
    "\n",
    "苦于一时想不起英文提示词的小伙伴，不仅可以从[文心官网](https://wenxin.baidu.com/ernie-vilg)体验该模型，还可以使用[PaddleNLP的pipeline](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/pipelines/examples/text_to_image)快速搭建属于自己的**ERNIE-ViLG 2.0 文生图系统**！\n",
    "\n",
    "本篇教程将带领大家如何快速定制属于自己的文图生成模型。\n",
    "\n",
    "| 模型                           | 语言 | 结构                    | 参数量 | 生成速度 | 图像大小 |\n",
    "| ----------------------------- | ---- | ------------------------- | ------ | --------- | -------- |\n",
    "| DALL-E Mini                   | 英文 | BART+VQGAN                | 484.7M | ~15s      | 256x256  |\n",
    "| 英文CLIP+Disco Diffusion       | 英文 | CLIP+Disco Diffusion      | 723.1M | ~10min    | 1024x768 |\n",
    "| **英文Stable Diffusion模型**        | 英文 | Diffusion Model      | 1066.2M | ~7s    | 512x512 |\n",
    "| 阿里EasyNLP文图生成模型          | 中文 | GPT+VQGAN                 | 173.4M | ~5s / ~0.5s | 256x256  |\n",
    "| 中文Ernie-ViL 2.0+Disco Diffusion  | 中文 | Ernie-ViL 2.0+Disco Diffusion | 775.6M | ~10min    | 1024x768 |\n",
    "| **文心ERNIE-ViLG 2.0**  | 中文 | Diffusion Model | Unknown | Unknown    | 1024x1024，1536x1024 等|\n",
    "\n",
    "# 图片展示\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/b7c99e3c98224ed3843873c3eca3961a702ca21683f14d3bba8e1f1c8aac2a14\" width=\"60%\" height=\"50%\"> <br />\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/eb36bb9639fc4b37a7021285bd842399f33d60cd8618433586e9de38fda963a4\" width=\"60%\" height=\"50%\"> <br />\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/99edab63c8754b218820f8eff72d127e0d696e85df68414298820f14f3ef4fb2\" width=\"60%\" height=\"50%\"> <br />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、Fork项目，进入 Notebook！\n",
    "\n",
    "点击“运行一下”后，再点击“启动环境\"，选择合适的GPU后即可进入项目。 AI Studio每天自动**赠送 8 小时**的GPU算力，显存更大的GPU能够生成尺寸更大的图片哦。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9319c725e55445458e0536a254e0825fa09f332bef524855899801ba0b12879b)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d07ebc951af14889bbb100e2714fe5c7203f0d2f2cf94f4680146d612e7e9d81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、运行下面的代码！\n",
    "\n",
    "进入之后，点击下边的框里左上角的“点击运行”按钮（或者点进下面的框内用快捷键 Ctrl + Enter）。\n",
    "\n",
    "**提示**：下面安装环境的代码，只需要在你**第一次进入本项目**时运行！\n",
    "\n",
    "等到显示“加载完毕, 请重启内核”后，请重启内核。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/12bb4a5a24fa4111b70b85aa89d64bceb7c98ea24fa54d0dba32c0e8610b412d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T08:22:46.186966Z",
     "iopub.status.busy": "2022-11-08T08:22:46.186178Z",
     "iopub.status.idle": "2022-11-08T08:22:54.773365Z",
     "shell.execute_reply": "2022-11-08T08:22:54.772232Z",
     "shell.execute_reply.started": "2022-11-08T08:22:46.186921Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完毕, 请重启内核\r\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from utils import diffusers_auto_update\n",
    "diffusers_auto_update()\n",
    "clear_output() # 清理很长的内容\n",
    "print('加载完毕, 请重启内核')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、重启内核！\n",
    "\n",
    "点击上边栏的“重启内核”！\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d9487d2c0b9d4467ad34a96abd60d6349802ced3ca2d483cb76bffe8415a24aa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 四、运行下面的代码快速体验\n",
    "> 最后一步，点击左上角的“点击运行”后，就会自动运行下面的代码，等几秒加载模型就可以玩耍啦~ **以后每次进来这个项目，就可以直接从这里开始运行啦~**\n",
    "\n",
    "**支持的预训练模型：**\n",
    "\n",
    "| ppdiffusers支持的模型名称    | huggingface对应的模型地址                           | Tips备注                                                     |\n",
    "| ---------------------------------------- | ---------------------------------------------------------- | -------------------------------------------------------------- |\n",
    "| CompVis/stable-diffusion-v1-4            | https://huggingface.co/CompVis/stable-diffusion-v1-4       | StableDiffusion第1-4版模型，可以画通用领域的图像。                 |\n",
    "| runwayml/stable-diffusion-v1-5            | https://huggingface.co/runwayml/stable-diffusion-v1-5       |StableDiffusion第1-5版模型，可以画通用领域的图像。                 |\n",
    "| hakurei/waifu-diffusion                  | https://huggingface.co/hakurei/waifu-diffusion             | Waifu v1-2的模型，主要适合画二次元图像！         |\n",
    "| hakurei/waifu-diffusion-v1-3             | https://huggingface.co/hakurei/waifu-diffusion             | Waifu v1-3的模型，主要适合画二次元图像！（对比v1-2更好！）         |\n",
    "| naclbit/trinart_stable_diffusion_v2_60k  | https://huggingface.co/naclbit/trinart_stable_diffusion_v2 | trinart 经过60k步数训练得到的模型，主要适合画二次元图像！ |\n",
    "| naclbit/trinart_stable_diffusion_v2_95k  | https://huggingface.co/naclbit/trinart_stable_diffusion_v2 | trinart 经过95k步数训练得到的模型，主要适合画二次元图像！ |\n",
    "| naclbit/trinart_stable_diffusion_v2_115k | https://huggingface.co/naclbit/trinart_stable_diffusion_v2 | trinart 经过115k步数训练得到的模型，主要适合画二次元图像！（并不是训练的步数更多效果更好！） |\n",
    "| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1  | https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 | Taiyi-Stable-Diffusion，支持中文语言！ |\n",
    "| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 | https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 | Taiyi-Stable-Diffusion，支持中英两种语言！ |\n",
    "\n",
    "**注意**:\n",
    "\n",
    "- 为了方便国内用户下载使用及快速体验**Stable Diffusion**模型，我们在百度云上提供了**paddle**版本的镜像权重。\n",
    "\n",
    "- 为了使用该模型与权重，你必须接受该模型所要求的**License**，请访问**Huggingface**的[Model Card](https://huggingface.co/runwayml/stable-diffusion-v1-5)， 仔细阅读里面的**许可证License**，然后签署该协议。\n",
    "\n",
    "**目前已有功能：**\n",
    "\n",
    "- ⭐**支持动态切换加载的模型名称**⭐： 目前所支持的模型，**如上表所示**。\n",
    "- ⭐**支持输入反面描述**⭐：反面描述可以使得生成图像的质量**远离**用户提供的**反面描述文本**。\n",
    "- ⭐**支持输入更长的文本**⭐：原版最大支持的长度为**77**，可通过修改**长度上限倍数**，使得模型能够接收更长的输入，如3倍，表示支持**3x77=231**个字符。\n",
    "- ⭐**支持自定义修改图像的高度和宽度**⭐：注意，生成更高的图片需要更好的**GPU配置**，如32G的V100，40G的A100显卡。\n",
    "- ⭐**支持批量生成图片并自动保存**⭐：可以批量生成多张**图片**与其对应的**参数**，并自动保存至指定目录。\n",
    "- ⭐**支持加载自己定制化训练的模型权重文件**⭐：可通过修改**需要导入的训练文件**，即可自动加载该文件目录底下的文件权重。\n",
    "- ⭐**支持各种常见的参数配置**⭐：如，修改推理步数、文本引导比例（cfg）、精度、随机种子和采样器等参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 文生图UI使用\n",
    "**重要参数解释：**\n",
    "\n",
    "- **negative_prompt反面描述**: 反面描述可以使得生成图像的质量**远离**用户提供的**反面描述文本**，如下图所示，原始图片会生成紫色的物体，当我们将\"purple\"设置成反面描述后，最终生成的人物就会远离紫色。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5451d6ffd2314588b03b847ef8625649e48debe1e4e5480b8db031c12e170126)\n",
    "\n",
    "- **推理的步数**：推理过程给图像去除噪音所需的步数，步数越大，图像的质量越高，但是推理速度会变慢。通常来说，我们无需增大推理步数，可选择20，30，50等步数即可。\n",
    "- **CFG(guidance_scale)**: 主要用来控制图片与提示词之间的相关程度。 **较高的引导值**，可以促使模型生成与文本提示词密切相关的图片。\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/27d35a548e574aa9ab704861478e9a0d3ed5cb83b8bd48d7b7ab353bcab057a5\" width=\"60%\" height=\"60%\"> <br />\n",
    "\n",
    "- **括号修改权重**：使用\"()\"或者\"{}\"可以加强文本中某个单词的权重，在下面的例子中，我们选择使用了\"()\"符号来表示增强文本权重。(2girl:1.3) 表示我们给“2girl”进行了强调，强调的倍率为1.3倍。(full_body) 表示我们给“full_body”进行了强调，强调的倍率为1.1倍（默认值，如果我们不指定倍率的话）。经过下面的强调，模型在生成图片时会更倾向于生成2个女孩！\n",
    "\n",
    "```\n",
    "prompt = \"best_quality (2girl:1.3) bow bride brown_hair closed_mouth frilled_bow frilled_hair_tubes frills (full_body) fox_ear hair_bow hair_tubes happy hood japanese_clothes kimono long_sleeves red_bow smile solo tabi uchikake white_kimono wide_sleeves cherry_blossoms\"\n",
    "```\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/6bf67455d92d4c218ab10173031a6a9afc67c49b5ef34568ab9abb40df5cde57\" width=\"90%\" height=\"80%\"> <br />\n",
    "\n",
    "- **长度上限倍数**：原版最大支持的长度为**77**，可通过修改**长度上限倍数**，使得模型能够接收更长的输入，如3倍，表示支持**3x77=231**个字符。\n",
    "- **随机数种子**：为了使得生成图片能够可复现，我们可以指定随机种子。\n",
    "- **采样器**：不同的采样器会有不同的结果，目前一共提供了三种，可以切换进行比较。\n",
    "- **精度**：模型推理使用的精度，选择**float16**可以加快模型的推理速度，但会牺牲部分的模型性能！\n",
    "- **超分模型**：可将生成的图片放大，变得高清！目前仅支持三种超分模型，**falsr_a**，**falsr_b**，**falsr_c**，可自行尝试。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8582897f91044876aa73fad8fd15985356e03e90d9c6445fbc7c425d37321632)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T08:48:58.885669Z",
     "iopub.status.busy": "2022-11-08T08:48:58.885237Z",
     "iopub.status.idle": "2022-11-08T08:49:02.870213Z",
     "shell.execute_reply": "2022-11-08T08:49:02.869114Z",
     "shell.execute_reply.started": "2022-11-08T08:48:58.885642Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b876f4cef14eacbe352c3bbff0e3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='couple couple rings surface from (Rainbow of Van Gogh:1.1), couple couple rings…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ui import gui_txt2img # 文生图\n",
    "display(gui_txt2img.gui) # 生成的图片自动保存到左侧的 outputs/txt2img 的文件夹里\n",
    "\n",
    "# 记得点击“生成图片”，才能出图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 图生图UI使用\n",
    "\n",
    "**重要参数解释：**\n",
    "\n",
    "- **需要转换的图片路径**: 即用户需要修改的底图，模型在底图上可以进行二次创作，下面的GIF动画使用了牧濑红莉栖（命运石之门动漫的女主）作为底图，而我们将会使用彩虹戒指作为底图！\n",
    "\n",
    "\n",
    "<center> <img src=\"https://ai-studio-static-online.cdn.bcebos.com/993df7205b2842b2a09d5b76b9c37024d1bfb9922a984981a8988bab28a80acc\" width=\"30%\" height=\"30%\"> <br /></center>\n",
    "\n",
    "\n",
    "- **修改强度**：我们提供的**初始图片作为起点**，当**修改强度**变得越大，**初始图片**上添加的**噪音**也就会变得越来越多，如下图所示，越往左，添加的噪音比率就越多，随着噪音的变多我们就无法分辨出原始图像了。\n",
    "\n",
    "<center> <img src=\"https://ai-studio-static-online.cdn.bcebos.com/28e8e97300714664bd87a8f98635b6df604bfc3046e2488c81a69e9bf673aa18\" width=\"60%\" height=\"40%\"> <br /></center>\n",
    "\n",
    "<center> <img src=\"https://ai-studio-static-online.cdn.bcebos.com/4ee889dc3ccf48d9a3f49554eab391cc706f06b7b7644264af13030311db9de8\"> <br /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T07:49:14.129090Z",
     "iopub.status.busy": "2022-11-03T07:49:14.128164Z",
     "iopub.status.idle": "2022-11-03T07:49:14.154185Z",
     "shell.execute_reply": "2022-11-03T07:49:14.153217Z",
     "shell.execute_reply.started": "2022-11-03T07:49:14.129048Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a3d5ff07f14b549a8a1ff1c5f7847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='couple couple rings surface from (Starry Night of Van Gogh:1.1), couple couple …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ui import gui_img2img # 图生图, 在左侧上传图片, 然后修改 \"需要转换的图片路径\"\n",
    "display(gui_img2img.gui) # 生成的图片自动保存到左侧的 outputs/img2img 的文件夹里\n",
    "\n",
    "# 记得点击“生成图片”，才能出图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 InPaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ui import gui_inpaint # inpaint\r\n",
    "display(gui_inpaint.gui) # 生成的图片自动保存到左侧的 outputs/inpaint 的文件夹里\r\n",
    "\r\n",
    "# 记得点击“生成图片”，才能出图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 超分UI使用\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/98a0599497584e23a40f699e5f26cd84e9ad51f0536548bea053746ee4e010fe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T07:49:55.873354Z",
     "iopub.status.busy": "2022-11-03T07:49:55.872296Z",
     "iopub.status.idle": "2022-11-03T07:49:55.884743Z",
     "shell.execute_reply": "2022-11-03T07:49:55.884003Z",
     "shell.execute_reply.started": "2022-11-03T07:49:55.873301Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8013424838e249e4afeede8b21380f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='resources/Ring.png', description='需要超分的图片路径', layout=Layout(width='100%'), style=De…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ui import gui_superres # 超分 (图片放大一倍), 在左侧“文件”目录上传图片, 然后修改 \"需要超分的图片路径\"\n",
    "display(gui_superres.gui) # 生成的图片自动保存到左侧的 outputs/highres 的文件夹里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 定制化训练（让模型认识新的物体或学习到新的风格）\n",
    "\n",
    "除了直接调用外，**PaddleNLP**还提供好用的二次开发能力，可以参照**下方**或[**PaddleNLP仓库**](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples)的教程，只需要几张图片，就可以定制属于自己的文图生成模型。\n",
    "\n",
    "如果对你有帮助，记得给PaddleNLP点个小小的Star⭐支持一下，PaddleNLP后续还会持续开源更多的能力，star收藏起来，不易走丢。开源不易，希望大家多多支持~ \n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/7f287240b16f4c4081d0b57ca808dce62769b13369434c64b9a26cfc48b6a978\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "GitHub地址：https://github.com/PaddlePaddle/PaddleNLP \n",
    "\n",
    "\n",
    "----------------\n",
    "<center> \n",
    "    <img src=\"https://textual-inversion.github.io/static/images/editing/colorful_teapot.JPG\" width=\"80%\" height=\"80%\">\n",
    "</center>\n",
    "\n",
    "[Textual inversion](https://arxiv.org/abs/2208.01618) 是一种个性化定制的文本生成图像(text2image)技术。我们只需要给模型提供 3-5 张图片，就可以训练个性化的Stable Diffusion模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在下面**GIF**例子中，我们进行了如下操作，更多信息可进入[PaddleNLP examples](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/textual_inversion)中查看更多例子。\n",
    "\n",
    "**(1)** 输入了代表该人物的**新单词**：\\<Alice\\>，新词用<>括起来，主要是为了避免与已有的单词混淆；\n",
    "\n",
    "**(2)** 指定了与该人物**比较接近的单词**：**girl**, 该单词作为先验（已知）知识，可以帮助模型快速理解新单词，从而加快模型训练；\n",
    "\n",
    "**(3)** 提供了含有下面**6张图片**的文件夹地址：**resources/Alices**，在这里我们指定了resources目录下的Alices文件夹。\n",
    "\n",
    "<center> <img src=\"https://ai-studio-static-online.cdn.bcebos.com/dcdfa7f8c35f4d5f9e0eeab7e590f5f4b576bb1728e94bb4a889b34d833397d2\" width=\"90%\" height=\"40%\"> <br /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/a75816b9719441a28bb3724e34b5eda4da027615b0814892bcb115e3467cbb94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T03:44:28.849852Z",
     "iopub.status.busy": "2022-11-01T03:44:28.848725Z",
     "iopub.status.idle": "2022-11-01T03:44:32.520984Z",
     "shell.execute_reply": "2022-11-01T03:44:32.519905Z",
     "shell.execute_reply.started": "2022-11-01T03:44:28.849779Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7462739301145768c4978594776b910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='需要学习什么？风格或实体', index=1, layout=Layout(width='100%'), options=('style', 'o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ui import gui_train_text_inversion # 训练\n",
    "display(gui_train_text_inversion.gui) # 训练结果会保存到 outputs/textual_inversion 的文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型训练完成之后，可以使用新模型预测了！**\n",
    "\n",
    "现在模型已经认识 \\<Alice\\> 这个object（人物、物体，everything...）了。\n",
    "\n",
    "比如输入Prompt：\\<Alice\\> at the lake，就可以生成一张站在湖边的 \\<Alice\\> 图像了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T04:01:58.799964Z",
     "iopub.status.busy": "2022-11-01T04:01:58.799569Z",
     "iopub.status.idle": "2022-11-01T04:01:58.822280Z",
     "shell.execute_reply": "2022-11-01T04:01:58.821272Z",
     "shell.execute_reply.started": "2022-11-01T04:01:58.799936Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c04bf87756a4722bf08009b393a0ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='<Alice> at the lake', description='prompt描述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ui import gui_text_inversion # 使用训练好的权重进行加载预测\n",
    "display(gui_text_inversion.gui) # 生成的图片自动保存到左侧的 outputs/text_inversion_txt2img 的文件夹里\n",
    "\n",
    "# 输入 <Alice> 相关的Prompt试试吧，例如：<Alice> at the lake，看看模型是否学到了<Alice>这个object。记得删除默认给出的negative_prompt反面描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**现在你已经学会了如何让模型认识新的物体，模型不仅可以学习新物体还可以学习新风格。风格的学习与物体的学习方法与流程一致，我们仅需在UI界面中设置学习“style”，开始训练即可。**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c86215be29e84c27886b922263ea73a715421671c42d495f89dbd4b9b2408d47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**欢迎各位贡献自己训练好的模型权重到PaddleNLP，比如\"xxx艺术家风格的模型\"，让更多开发者了解、使用自己的作品。欢迎加入交流群，了解如何贡献。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、 加入交流群，一起创造吧\n",
    "\n",
    "以上实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**如果对您有帮助，记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐，收藏起来，不易走丢~**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/7f287240b16f4c4081d0b57ca808dce62769b13369434c64b9a26cfc48b6a978\" width=\"80%\" height=\"80%\"> <br />\n",
    "\n",
    "**直播课回放：**\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/3d51b7d1a60349e08d268afa2ec6716d507a25d17ea147feb40c65dd74dfa372\" width=\"25%\" height=\"25%\"> <br />\n",
    "\n",
    "如何快速了解、掌握和应用大模型？如何有效触发、管理和协同AI创造力？面向设计教学、科研和产业应用，我们该如何与文心大模型一起携手，探索AIGC驱动下人机交互新范式。\n",
    "\n",
    "11月4日，在“AIGC时代下的人机共创”工作坊中，百度资深研发工程师和AI艺术界大咖，由浅入深、由宽入专地向大家娓娓道来AIGC的全景图，为设计领域学者和从业者、交叉学科研究者和爱好者，提供有益参考。加入交流群可获取回放。\n",
    "\n",
    "\n",
    "- **加入交流群，一起创造吧**\n",
    "\n",
    "如果对NLP模型二次开发技术感兴趣，欢迎加入PaddleNLP**微信群**交流：\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/15c03edd2d164a04bc566a55935fe33f41051787f9ae44de9a71c36fb2d3a9b3\" width=\"25%\" height=\"25%\"> <br />\n",
    "\n",
    "\n",
    "\n",
    "也可以加入**QQ群**，交流文图趣味应用。\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/de62713000a641d28c74d3174aaf517d78a4801e422f4e2788d5f890b272760b\" width=\"25%\" height=\"25%\"> <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、参考资料\n",
    "\n",
    "- https://github.com/PaddlePaddle/PaddleNLP\n",
    "- https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features\n",
    "- https://github.com/huggingface/diffusers\n",
    "- https://github.com/CompVis/stable-diffusion\n",
    "- https://arxiv.org/pdf/2006.11239.pdf\n",
    "- https://arxiv.org/pdf/2208.01618.pdf\n",
    "- https://huggingface.co/runwayml/stable-diffusion-v1-5 (请注意里面使用的LICENSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "02171df25bfaf2d4dd046004a91568a270b3a8e32f8815a8efc9d94f8a69beff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
